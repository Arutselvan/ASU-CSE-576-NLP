{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "paracrawl_task_instances",
      "provenance": [],
      "authorship_tag": "ABX9TyOzcG+7+zeAxVUSYXSubYde",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Arutselvan/ASU-CSE-576-NLP/blob/main/HW_2/paracrawl_task_instances.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3luQIt8OzbF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f992017-ea52-4343-c956-496530383402"
      },
      "source": [
        "!pip install datasets"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (1.11.0)\n",
            "Requirement already satisfied: huggingface-hub<0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.0.16)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.6.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n",
            "Requirement already satisfied: tqdm>=4.42 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.62.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n",
            "Requirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2021.8.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets) (3.0.12)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (2.4.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.5.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EwAODpoPHTm"
      },
      "source": [
        "from datasets import load_dataset, concatenate_datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRl_JDn2SR3S"
      },
      "source": [
        "iso_369_codes = [('ab', 'Abkhaz'),\n",
        "('aa', 'Afar'),\n",
        "('af', 'Afrikaans'),\n",
        "('ak', 'Akan'),\n",
        "('sq', 'Albanian'),\n",
        "('am', 'Amharic'),\n",
        "('ar', 'Arabic'),\n",
        "('an', 'Aragonese'),\n",
        "('hy', 'Armenian'),\n",
        "('as', 'Assamese'),\n",
        "('av', 'Avaric'),\n",
        "('ae', 'Avestan'),\n",
        "('ay', 'Aymara'),\n",
        "('az', 'Azerbaijani'),\n",
        "('bm', 'Bambara'),\n",
        "('ba', 'Bashkir'),\n",
        "('eu', 'Basque'),\n",
        "('be', 'Belarusian'),\n",
        "('bn', 'Bengali'),\n",
        "('bh', 'Bihari'),\n",
        "('bi', 'Bislama'),\n",
        "('bs', 'Bosnian'),\n",
        "('br', 'Breton'),\n",
        "('bg', 'Bulgarian'),\n",
        "('my', 'Burmese'),\n",
        "('ca', 'Catalan; Valencian'),\n",
        "('ch', 'Chamorro'),\n",
        "('ce', 'Chechen'),\n",
        "('ny', 'Chichewa; Chewa; Nyanja'),\n",
        "('zh', 'Chinese'),\n",
        "('cv', 'Chuvash'),\n",
        "('kw', 'Cornish'),\n",
        "('co', 'Corsican'),\n",
        "('cr', 'Cree'),\n",
        "('hr', 'Croatian'),\n",
        "('cs', 'Czech'),\n",
        "('da', 'Danish'),\n",
        "('dv', 'Divehi; Maldivian;'),\n",
        "('nl', 'Dutch'),\n",
        "('dz', 'Dzongkha'),\n",
        "('en', 'English'),\n",
        "('eo', 'Esperanto'),\n",
        "('et', 'Estonian'),\n",
        "('ee', 'Ewe'),\n",
        "('fo', 'Faroese'),\n",
        "('fj', 'Fijian'),\n",
        "('fi', 'Finnish'),\n",
        "('fr', 'French'),\n",
        "('ff', 'Fula'),\n",
        "('gl', 'Galician'),\n",
        "('ka', 'Georgian'),\n",
        "('de', 'German'),\n",
        "('el', 'Greek, Modern'),\n",
        "('gn', 'Guaraní'),\n",
        "('gu', 'Gujarati'),\n",
        "('ht', 'Haitian'),\n",
        "('ha', 'Hausa'),\n",
        "('he', 'Hebrew (modern)'),\n",
        "('hz', 'Herero'),\n",
        "('hi', 'Hindi'),\n",
        "('ho', 'Hiri Motu'),\n",
        "('hu', 'Hungarian'),\n",
        "('ia', 'Interlingua'),\n",
        "('id', 'Indonesian'),\n",
        "('ie', 'Interlingue'),\n",
        "('ga', 'Irish'),\n",
        "('ig', 'Igbo'),\n",
        "('ik', 'Inupiaq'),\n",
        "('io', 'Ido'),\n",
        "('is', 'Icelandic'),\n",
        "('it', 'Italian'),\n",
        "('iu', 'Inuktitut'),\n",
        "('ja', 'Japanese'),\n",
        "('jv', 'Javanese'),\n",
        "('kl', 'Kalaallisut'),\n",
        "('kn', 'Kannada'),\n",
        "('kr', 'Kanuri'),\n",
        "('ks', 'Kashmiri'),\n",
        "('kk', 'Kazakh'),\n",
        "('km', 'Khmer'),\n",
        "('ki', 'Kikuyu, Gikuyu'),\n",
        "('rw', 'Kinyarwanda'),\n",
        "('ky', 'Kirghiz, Kyrgyz'),\n",
        "('kv', 'Komi'),\n",
        "('kg', 'Kongo'),\n",
        "('ko', 'Korean'),\n",
        "('ku', 'Kurdish'),\n",
        "('kj', 'Kwanyama, Kuanyama'),\n",
        "('la', 'Latin'),\n",
        "('lb', 'Luxembourgish'),\n",
        "('lg', 'Luganda'),\n",
        "('li', 'Limburgish'),\n",
        "('ln', 'Lingala'),\n",
        "('lo', 'Lao'),\n",
        "('lt', 'Lithuanian'),\n",
        "('lu', 'Luba-Katanga'),\n",
        "('lv', 'Latvian'),\n",
        "('gv', 'Manx'),\n",
        "('mk', 'Macedonian'),\n",
        "('mg', 'Malagasy'),\n",
        "('ms', 'Malay'),\n",
        "('ml', 'Malayalam'),\n",
        "('mt', 'Maltese'),\n",
        "('mi', 'Māori'),\n",
        "('mr', 'Marathi (Marāṭhī)'),\n",
        "('mh', 'Marshallese'),\n",
        "('mn', 'Mongolian'),\n",
        "('na', 'Nauru'),\n",
        "('nv', 'Navajo, Navaho'),\n",
        "('nb', 'Norwegian Bokmål'),\n",
        "('nd', 'North Ndebele'),\n",
        "('ne', 'Nepali'),\n",
        "('ng', 'Ndonga'),\n",
        "('nn', 'Norwegian Nynorsk'),\n",
        "('no', 'Norwegian'),\n",
        "('ii', 'Nuosu'),\n",
        "('nr', 'South Ndebele'),\n",
        "('oc', 'Occitan'),\n",
        "('oj', 'Ojibwe, Ojibwa'),\n",
        "('cu', 'Old Church Slavonic'),\n",
        "('om', 'Oromo'),\n",
        "('or', 'Oriya'),\n",
        "('os', 'Ossetian, Ossetic'),\n",
        "('pa', 'Panjabi, Punjabi'),\n",
        "('pi', 'Pāli'),\n",
        "('fa', 'Persian'),\n",
        "('pl', 'Polish'),\n",
        "('ps', 'Pashto, Pushto'),\n",
        "('pt', 'Portuguese'),\n",
        "('qu', 'Quechua'),\n",
        "('rm', 'Romansh'),\n",
        "('rn', 'Kirundi'),\n",
        "('ro', 'Romanian, Moldavan'),\n",
        "('ru', 'Russian'),\n",
        "('sa', 'Sanskrit (Saṁskṛta)'),\n",
        "('sc', 'Sardinian'),\n",
        "('sd', 'Sindhi'),\n",
        "('se', 'Northern Sami'),\n",
        "('sm', 'Samoan'),\n",
        "('sg', 'Sango'),\n",
        "('sr', 'Serbian'),\n",
        "('gd', 'Scottish Gaelic'),\n",
        "('sn', 'Shona'),\n",
        "('si', 'Sinhala, Sinhalese'),\n",
        "('sk', 'Slovak'),\n",
        "('sl', 'Slovene'),\n",
        "('so', 'Somali'),\n",
        "('st', 'Southern Sotho'),\n",
        "('es', 'Spanish; Castilian'),\n",
        "('su', 'Sundanese'),\n",
        "('sw', 'Swahili'),\n",
        "('ss', 'Swati'),\n",
        "('sv', 'Swedish'),\n",
        "('ta', 'Tamil'),\n",
        "('te', 'Telugu'),\n",
        "('tg', 'Tajik'),\n",
        "('th', 'Thai'),\n",
        "('ti', 'Tigrinya'),\n",
        "('bo', 'Tibetan'),\n",
        "('tk', 'Turkmen'),\n",
        "('tl', 'Tagalog'),\n",
        "('tn', 'Tswana'),\n",
        "('to', 'Tonga'),\n",
        "('tr', 'Turkish'),\n",
        "('ts', 'Tsonga'),\n",
        "('tt', 'Tatar'),\n",
        "('tw', 'Twi'),\n",
        "('ty', 'Tahitian'),\n",
        "('ug', 'Uighur, Uyghur'),\n",
        "('uk', 'Ukrainian'),\n",
        "('ur', 'Urdu'),\n",
        "('uz', 'Uzbek'),\n",
        "('ve', 'Venda'),\n",
        "('vi', 'Vietnamese'),\n",
        "('vo', 'Volapük'),\n",
        "('wa', 'Walloon'),\n",
        "('cy', 'Welsh'),\n",
        "('wo', 'Wolof'),\n",
        "('fy', 'Western Frisian'),\n",
        "('xh', 'Xhosa'),\n",
        "('yi', 'Yiddish'),\n",
        "('yo', 'Yoruba'),\n",
        "('za', 'Zhuang, Chuang'),\n",
        "('zu', 'Zulu')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFPUR6EVTJQ8"
      },
      "source": [
        "lang_code_map = {}\n",
        "\n",
        "for code,lang in iso_369_codes:\n",
        "  lang_code_map[code] = lang"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dduLf3iUTbOJ",
        "outputId": "c7029d4e-6545-4b2a-c041-22bd95d57293"
      },
      "source": [
        "en_so_dataset = load_dataset(\"opus_paracrawl\", \"en-so\")\n",
        "en_so_dataset = en_so_dataset.shuffle()\n",
        "en_so_dataset = concatenate_datasets([en_so_dataset['train']])\n",
        "\n",
        "english_to_somali_instances = []\n",
        "\n",
        "for transl in en_so_dataset:\n",
        "  english_to_somali_instances.append({\n",
        "      \"input\": \"English sentence: \" + transl['translation']['en'],\n",
        "      \"output\": [transl['translation']['so']]\n",
        "  })\n",
        "\n",
        "english_to_somali_instances = english_to_somali_instances[:6000]\n",
        "\n",
        "len(english_to_somali_instances)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reusing dataset opus_para_crawl (/root/.cache/huggingface/datasets/opus_para_crawl/en-so/1.0.0/d0becb3ac754eb295ccf6b4b87f391d12d2f4217dbc4f87f2a9718ba1f2de4a3)\n",
            "Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/opus_para_crawl/en-so/1.0.0/d0becb3ac754eb295ccf6b4b87f391d12d2f4217dbc4f87f2a9718ba1f2de4a3/cache-433f9a64a0d5a594.arrow\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6000"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kk6hogu2X0dl",
        "outputId": "8107c7b1-63d3-49e5-f4e4-04086807ae6d"
      },
      "source": [
        "en_tl_dataset = load_dataset(\"opus_paracrawl\", \"en-tl\")\n",
        "en_tl_dataset = en_tl_dataset.shuffle()\n",
        "en_tl_dataset = concatenate_datasets([en_tl_dataset['train']])\n",
        "\n",
        "english_to_tagalog_instances = []\n",
        "\n",
        "for transl in en_tl_dataset:\n",
        "  english_to_tagalog_instances.append({\n",
        "      \"input\": \"English sentence: \" + transl['translation']['en'],\n",
        "      \"output\": [transl['translation']['tl']]\n",
        "  })\n",
        "\n",
        "english_to_tagalog_instances = english_to_tagalog_instances[:6000]\n",
        "\n",
        "len(english_to_tagalog_instances)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reusing dataset opus_para_crawl (/root/.cache/huggingface/datasets/opus_para_crawl/en-tl/1.0.0/d0becb3ac754eb295ccf6b4b87f391d12d2f4217dbc4f87f2a9718ba1f2de4a3)\n",
            "Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/opus_para_crawl/en-tl/1.0.0/d0becb3ac754eb295ccf6b4b87f391d12d2f4217dbc4f87f2a9718ba1f2de4a3/cache-741f1c2b17191bbe.arrow\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6000"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUMVLizrY0dQ",
        "outputId": "9305d7b6-f60c-4143-a5ca-c72938eb0ad3"
      },
      "source": [
        "en_ig_dataset = load_dataset(\"opus_paracrawl\", \"en-ig\")\n",
        "en_ig_dataset = en_ig_dataset.shuffle()\n",
        "en_ig_dataset = concatenate_datasets([en_ig_dataset['train']])\n",
        "\n",
        "igbo_to_english_instances = []\n",
        "\n",
        "for transl in en_ig_dataset:\n",
        "  igbo_to_english_instances.append({\n",
        "      \"input\": \"Igbo sentence: \" + transl['translation']['ig'],\n",
        "      \"output\": [transl['translation']['en']]\n",
        "  })\n",
        "\n",
        "igbo_to_english_instances = igbo_to_english_instances[:6000]\n",
        "\n",
        "len(igbo_to_english_instances)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reusing dataset opus_para_crawl (/root/.cache/huggingface/datasets/opus_para_crawl/en-ig/1.0.0/d0becb3ac754eb295ccf6b4b87f391d12d2f4217dbc4f87f2a9718ba1f2de4a3)\n",
            "Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/opus_para_crawl/en-ig/1.0.0/d0becb3ac754eb295ccf6b4b87f391d12d2f4217dbc4f87f2a9718ba1f2de4a3/cache-57062474b19fd443.arrow\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6000"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gk-FJphlapZm",
        "outputId": "9499232b-0b1a-4bb1-d552-2db28b744bb2"
      },
      "source": [
        "fr_nl_dataset = load_dataset(\"opus_paracrawl\", \"fr-nl\")\n",
        "fr_nl_dataset = fr_nl_dataset.shuffle()\n",
        "fr_nl_dataset = concatenate_datasets([fr_nl_dataset['train']])\n",
        "fr_nl_dataset[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reusing dataset opus_para_crawl (/root/.cache/huggingface/datasets/opus_para_crawl/fr-nl/1.0.0/d0becb3ac754eb295ccf6b4b87f391d12d2f4217dbc4f87f2a9718ba1f2de4a3)\n",
            "Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/opus_para_crawl/fr-nl/1.0.0/d0becb3ac754eb295ccf6b4b87f391d12d2f4217dbc4f87f2a9718ba1f2de4a3/cache-4c2af9d6d43b8fe9.arrow\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': '136866',\n",
              " 'translation': {'fr': \"Il peut se produire d'ozone également O 3 et de ses produits de réaction, des silicates et des substances gazeuses autres, très nuire à la santé.\",\n",
              "  'nl': 'Er kunnen OOK ozon optreden O 3 en de reactieproducten daarvan, gasvormige silicaten en andere stoffen, zeer schadelijk zijn voor de gezondheid.'}}"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVGKC3bFcIxs",
        "outputId": "9990b278-4b9b-4e40-ba5f-e8b48c25e05c"
      },
      "source": [
        "identify_lang_instances = []\n",
        "\n",
        "for i in range(1200):\n",
        "  identify_lang_instances.append({\n",
        "      \"input\": \"Text: \" + fr_nl_dataset[i]['translation']['fr'],\n",
        "      \"output\": [lang_code_map['fr']]\n",
        "  })\n",
        "  identify_lang_instances.append({\n",
        "      \"input\": \"Text: \" + fr_nl_dataset[i]['translation']['nl'],\n",
        "      \"output\": [lang_code_map['nl']]\n",
        "  })\n",
        "  identify_lang_instances.append({\n",
        "      \"input\": \"Text: \" + en_so_dataset[i]['translation']['en'],\n",
        "      \"output\": [lang_code_map['en']]\n",
        "  })\n",
        "  identify_lang_instances.append({\n",
        "      \"input\": \"Text: \" + en_so_dataset[i]['translation']['so'],\n",
        "      \"output\": [lang_code_map['so']]\n",
        "  })\n",
        "  identify_lang_instances.append({\n",
        "      \"input\": \"Text: \" + en_tl_dataset[i]['translation']['tl'],\n",
        "      \"output\": [lang_code_map['tl']]\n",
        "  })\n",
        "\n",
        "len(identify_lang_instances)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6000"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Rr8xaMO6wKz"
      },
      "source": [
        "import json\n",
        "\n",
        "CONTRIBUTOR = \"Arut Selvan Dhanasekaran\"\n",
        "SOURCE = \"opus_paracrawl\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMG3syysghhi"
      },
      "source": [
        "#Task 1\n",
        "\n",
        "definition_1 = \"Given a sentence in English language, translate the sentence to Somali language keeping the meaning of the original sentence intact\"\n",
        "\n",
        "positive_examples_1 = [{\n",
        "    \"input\": \"English sentence: Lionel Messi is the greatest football player of all time\",\n",
        "    \"output\": \"Lionel Messi waa ciyaaryahanka ugu weyn kubadda cagta abid\",\n",
        "    \"explanation\": \"The output exactly translates the sentence to it's somali equivalent. Even though the phrase 'greatest player of all times' is translated to 'greatest player ever', the meaning remains the same.\"\n",
        "},\n",
        "{\n",
        "    \"input\": \"English sentence: Photosynthesis is a method used by plants and other organisms to convert light energy into chemical energy\",\n",
        "    \"output\": \"Photosynthesis waa hab ay adeegsadaan dhirta iyo noolaha kale si ay tamarta iftiinka ugu beddelaan tamar kiimiko.\",\n",
        "    \"explanation\": \"The output is the exact Somali translation of the input English text.\"\n",
        "},\n",
        "{\n",
        "    \"input\": \"English sentence: I ate cereal for breakfast\",\n",
        "    \"output\": \"Waxaan cunay badarka quraacda\",\n",
        "    \"explanation\": \"The Somali translation exactly means the same as the input English sentence.\"\n",
        "}]\n",
        "\n",
        "negative_examples_1 = [{\n",
        "    \"input\": \"English sentence: The first Italian Grand Prix took place on 4 September 1921 at a 10.7-mile (17.3 km) circuit near Montichiari\",\n",
        "    \"output\": \"Tartanka Grand Prix-kii ugu horreeyay ee Talyaanigu wuxuu dhacay 4tii Sebtember 1921 goob 10.7-mayl (17.3 km) u dhow Montichiari\",\n",
        "    \"explanation\": \"Even though the sentence says the 'first Italian grand prix', the somali translation say's 'Italy's first grand prix' which is wrong as Italy had grand prix races before but it was not name the Italian grand prix.\"\n",
        "},\n",
        "{\n",
        "    \"input\": \"English sentence: The human stomach can dissolve razor blades\",\n",
        "    \"output\": \"Caloosha bani -aadmigu waxay kala diri kartaa baalasha\",\n",
        "    \"explanation\": \"The Somali translation of the english sentence means 'Human stomach can expand it's wings' which is wrong\"\n",
        "},\n",
        "{\n",
        "    \"input\": \"English sentence: We are only as strong as we are united, as weak as we are divided\",\n",
        "    \"output\": \"Waxaan nahay uun sida aan u midowno, sida aan u kala qaybsannahay\",\n",
        "    \"explanation\": \"The Somali translation 'We are just how united we are, how divided we are' does not make any sense and it's not the actual translation of the original english sentence.\"\n",
        "}]\n",
        "\n",
        "temp_set = set()\n",
        "\n",
        "for x in positive_examples_1:\n",
        "  temp_set.add(x['input'])\n",
        "\n",
        "for x in negative_examples_1:\n",
        "  temp_set.add(x['input'])\n",
        "\n",
        "ets_cleaned = []\n",
        "\n",
        "for instance in english_to_somali_instances:\n",
        "  if instance['input'] not in temp_set:\n",
        "    temp_set.add(instance['input'])\n",
        "    ets_cleaned.append(instance)\n",
        "\n",
        "task_1 = {\n",
        "    \"Contributors\": [CONTRIBUTOR],\n",
        "    \"Source\": [SOURCE],\n",
        "    \"Categories\": [\"Text Translation\"],\n",
        "    \"Definition\": definition_1,\n",
        "    \"Positive Examples\": positive_examples_1,\n",
        "    \"Negative Examples\": negative_examples_1,\n",
        "    \"Instances\": ets_cleaned\n",
        "}\n",
        "\n",
        "with open(\"task149_opus_paracrawl_translation.json\", 'w') as fout:\n",
        "    json_dumps_str = json.dumps(task_1, indent=4)\n",
        "    print(json_dumps_str, file=fout)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOZt_NY426hL"
      },
      "source": [
        "# Task 2\n",
        "\n",
        "definition_2 = \"A piece of text from one of these 5 languages - French, English, Dutch, Somali, Tagalog is given. Identify the language to which the text belongs.\"\n",
        "\n",
        "positive_examples_2 = [{\n",
        "    \"input\": \"Text: Cheval de soins pour les enfants de 3 ans!\",\n",
        "    \"output\": \"French\",\n",
        "    \"explanation\": \"The given text is in French language\"\n",
        "},\n",
        "{\n",
        "    \"input\": \"Text: Welke kleuren zijn nu in de mode?\",\n",
        "    \"output\": \"Dutch\",\n",
        "    \"explanation\": \"The text is a question in Dutch language\"\n",
        "},\n",
        "{\n",
        "    \"input\": \"Text: Harry Potter disarmed Voldermort during the battle of Hogwarts\",\n",
        "    \"output\": \"English\",\n",
        "    \"explanation\": \"The given piece of text is in English\"\n",
        "}]\n",
        "\n",
        "negative_examples_2 = [{\n",
        "    \"input\": \"Text: Wat is diabetes type 2?\",\n",
        "    \"output\": \"English\",\n",
        "    \"explanation\": \"Even though some of the words belong to English, the word 'Wat' is actually Dutch and it makes the given sentence Dutch. So the correct answer should have been Dutch.\"\n",
        "},\n",
        "{\n",
        "    \"input\": \"Text: Qu'en est-il de vos effectifs en 2019 ?\",\n",
        "    \"output\": \"Somali\",\n",
        "    \"explanation\": \"The input sentence is in French, not Somali.\"\n",
        "},\n",
        "{\n",
        "    \"input\": \"Text: Liiska tusmada muuqaalka ee Sentinel 2 iyo Landsat\",\n",
        "    \"output\": \"Tagalog\",\n",
        "    \"explanation\": \"The given piece of text belong to the Somali language but was incorrectly identified as Tagalog\"\n",
        "}]\n",
        "\n",
        "temp_set = set()\n",
        "\n",
        "for x in positive_examples_2:\n",
        "  temp_set.add(x['input'])\n",
        "\n",
        "for x in negative_examples_2:\n",
        "  temp_set.add(x['input'])\n",
        "\n",
        "ili_cleaned = []\n",
        "\n",
        "for instance in identify_lang_instances:\n",
        "  if instance['input'] not in temp_set:\n",
        "    temp_set.add(instance['input'])\n",
        "    ili_cleaned.append(instance)\n",
        "\n",
        "task_2 = {\n",
        "    \"Contributors\": [CONTRIBUTOR],\n",
        "    \"Source\": [SOURCE],\n",
        "    \"Categories\": [\"Text Classification\"],\n",
        "    \"Definition\": definition_2,\n",
        "    \"Positive Examples\": positive_examples_2,\n",
        "    \"Negative Examples\": negative_examples_2,\n",
        "    \"Instances\": ili_cleaned\n",
        "}\n",
        "\n",
        "with open(\"task150_opus_paracrawl_classification.json\", 'w') as fout:\n",
        "    json_dumps_str = json.dumps(task_2, indent=4)\n",
        "    print(json_dumps_str, file=fout)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VHb1kbqr91X"
      },
      "source": [
        "# Task 3\n",
        "\n",
        "definition_3 = \"Given a sentence in English language, translate the sentence to Tagalog language keeping the meaning of the original sentence intact.\"\n",
        "\n",
        "\n",
        "positive_examples_3 = [{\n",
        "    \"input\": \"English sentence: Roger Federer was the first player to win 20 Grand Slams\",\n",
        "    \"output\": \"Si Roger Federer ang unang manlalaro na nanalo ng 20 Grand Slams\",\n",
        "    \"explanation\": \"The output is an exact translation of the English sentence to it's Tagalog equivalent and meaning remains the same.\"\n",
        "},\n",
        "{\n",
        "    \"input\": \"English sentence: A manufacturer of led flashing light 5 watt at GuangDong China.\",\n",
        "    \"output\": \"Ang tagagawa ng LED panggayak liwanag sa Guangdong China.\",\n",
        "    \"explanation\": \"The output is the exact Tagalog translation of the input English text.\"\n",
        "},\n",
        "{\n",
        "    \"input\": \"English sentence: 22:48 God who giveth me revenge, and bringest down people under me\",\n",
        "    \"output\": \"22:48 Sa makatuwid baga'y ang Dios na ipinanghihiganti ako. At pinangangayupapa sa akin ang mga bayan\",\n",
        "    \"explanation\": \"The Tagalog translation exactly means the same as the input English sentence.\"\n",
        "}]\n",
        "\n",
        "negative_examples_3 = [{\n",
        "    \"input\": \"English sentence: It does not do to dwell on dreams and forget to live\",\n",
        "    \"output\": \"Hindi nito nagagawa upang mapag-isipan ang mga pangarap at kalimutan na mabuhay.\",\n",
        "    \"explanation\": \"The Tagalog translation contains extra words which changes the meaning of the original English text.\"\n",
        "},\n",
        "{\n",
        "    \"input\": \"English sentence: Call me in the morning, I'll be on my way\",\n",
        "    \"output\": \"Tawagan mo ako sa umaga, papunta na ako\",\n",
        "    \"explanation\": \"The Tagalog translation changes the tense from future tense to present tense.\"\n",
        "},\n",
        "{\n",
        "    \"input\": \"English sentence: There will not be any charge for a declined recurring debit card transaction\",\n",
        "    \"output\": \"May sisingilin para sa isang tinanggihan na paulit-ulit na transaksyon sa debit card\",\n",
        "    \"explanation\": \"The Taglog translation actually implies the exact opposite meaning of the input English sentence\"\n",
        "}]\n",
        "\n",
        "temp_set = set()\n",
        "\n",
        "for x in positive_examples_3:\n",
        "  temp_set.add(x['input'])\n",
        "\n",
        "for x in negative_examples_3:\n",
        "  temp_set.add(x['input'])\n",
        "\n",
        "ett_cleaned = []\n",
        "\n",
        "for instance in english_to_tagalog_instances:\n",
        "  if instance['input'] not in temp_set:\n",
        "    temp_set.add(instance['input'])\n",
        "    ett_cleaned.append(instance)\n",
        "\n",
        "\n",
        "task_3 = {\n",
        "    \"Contributors\": [CONTRIBUTOR],\n",
        "    \"Source\": [SOURCE],\n",
        "    \"Categories\": [\"Text Translation\"],\n",
        "    \"Definition\": definition_3,\n",
        "    \"Positive Examples\": positive_examples_3,\n",
        "    \"Negative Examples\": negative_examples_3,\n",
        "    \"Instances\": ett_cleaned\n",
        "}\n",
        "\n",
        "with open(\"task151_opus_paracrawl_translation.json\", 'w') as fout:\n",
        "    json_dumps_str = json.dumps(task_3, indent=4)\n",
        "    print(json_dumps_str, file=fout)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIDxIktLx4-o"
      },
      "source": [
        "# Task 4\n",
        "\n",
        "definition_4 = \"Given a sentence in Igbo language, translate the sentence to English language keeping the meaning of the original sentence intact\"\n",
        "\n",
        "positive_examples_4 = [{\n",
        "    \"input\": \"Igbo sentence: Olee kwere omume?\",\n",
        "    \"output\": \"How is this possible\",\n",
        "    \"explanation\": \"The English translation means the same as the original sentence in the Igbo language.\"\n",
        "},\n",
        "{\n",
        "    \"input\": \"Igbo sentence: ututu oma onye obula\",\n",
        "    \"output\": \"good morning everyone\",\n",
        "    \"explanation\": \"The output is the exact English translation of the input Igbo text.\"\n",
        "},\n",
        "{\n",
        "    \"input\": \"Igbo sentence: Agara m ịhụ mwepụta nke Apollo 5\",\n",
        "    \"output\": \"I went to see the launch of the Apollo 5\",\n",
        "    \"explanation\": \"The English translation exactly means the same as the input Igbo sentence.\"\n",
        "}]\n",
        "\n",
        "negative_examples_4 = [{\n",
        "    \"input\": \"Igbo sentence: Sebastian Vettel na -anya ụgbọ ala maka Aston Martin\",\n",
        "    \"output\": \"Aston Martin is married to Sebastian Vettel\",\n",
        "    \"explanation\": \"The English translation is not all relevant to the original Igbo sentence.\"\n",
        "},\n",
        "{\n",
        "    \"input\": \"Olileanya bụ ihe dị mma\",\n",
        "    \"output\": \"Hope is not a good thing\",\n",
        "    \"explanation\": \"The English translation actually implies the exact opposite meaning of the input Igbo sentence\"\n",
        "},\n",
        "{\n",
        "    \"input\": \"Igbo sentence: Eri m nri sanwichi maka nri abalị\",\n",
        "    \"output\": \"I'm eating a sandwich for dinner\",\n",
        "    \"explanation\": \"Even though the meaning is almost the same, the English translation changes the tense from past to present\"\n",
        "}]\n",
        "\n",
        "temp_set = set()\n",
        "\n",
        "for x in positive_examples_4:\n",
        "  temp_set.add(x['input'])\n",
        "\n",
        "for x in negative_examples_4:\n",
        "  temp_set.add(x['input'])\n",
        "\n",
        "ite_cleaned = []\n",
        "\n",
        "for instance in igbo_to_english_instances:\n",
        "  if instance['input'] not in temp_set:\n",
        "    temp_set.add(instance['input'])\n",
        "    ite_cleaned.append(instance)\n",
        "\n",
        "task_4 = {\n",
        "    \"Contributors\": [CONTRIBUTOR],\n",
        "    \"Source\": [SOURCE],\n",
        "    \"Categories\": [\"Text Translation\"],\n",
        "    \"Definition\": definition_4,\n",
        "    \"Positive Examples\": positive_examples_4,\n",
        "    \"Negative Examples\": negative_examples_4,\n",
        "    \"Instances\": ite_cleaned\n",
        "}\n",
        "\n",
        "with open(\"task152_opus_paracrawl_translation.json\", 'w') as fout:\n",
        "    json_dumps_str = json.dumps(task_4, indent=4)\n",
        "    print(json_dumps_str, file=fout)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}